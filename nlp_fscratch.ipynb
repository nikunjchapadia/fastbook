{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_fscratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOigc1IadyY4iCI3yyqbeG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikunjchapadia/fastbook/blob/master/nlp_fscratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYX4TkDoHefc",
        "outputId": "fc75515d-cf83-4786-d368-ecaafd45d53d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 189 kB 42.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 33.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 558 kB 36.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 241 kB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 44.2 MB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastbook import *"
      ],
      "metadata": {
        "id": "DeDGhsXdHmAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.text.all import *\n",
        "# first 10,000 numbers reterun in english \n",
        "path = untar_data(URLs.HUMAN_NUMBERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "4z1pwFM9IghR",
        "outputId": "32b0b3b2-a985-41c0-9fcc-a0b7c8b89d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='32768' class='' max='30252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      108.32% [32768/30252 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path.BASE_PATH = path"
      ],
      "metadata": {
        "id": "f3k352BdIjEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1pzvRU7Ik3P",
        "outputId": "ebb83101-5c7f-4936-fd17-0d177e00f908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('valid.txt'),Path('train.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = L()\n",
        "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: lines += L(*f.readlines())\n",
        "lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLLyDgeuIzyo",
        "outputId": "d678d0c2-8c30-43e0-b2c6-577a446cdd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' . '.join([l.strip() for l in lines])\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "SwSZfFW_I6fy",
        "outputId": "29a350e7-33c0-4701-bf54-1a15c0229f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split(' ')\n",
        "tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04hUPFYYI978",
        "outputId": "3db58cfc-7207-425e-feb0-b52a2357e80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = L(*tokens).unique()\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbBgpOfmJArq",
        "outputId": "bd9d3a92-45ed-496f-9f53-c28d0fa15665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "nums = L(word2idx[i] for i in tokens)\n",
        "tokens, nums"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll4TioPOJE6_",
        "outputId": "dae93f4a-0e9e-4a6a-967c-fa4e159ee633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['one',\n",
              "  '.',\n",
              "  'two',\n",
              "  '.',\n",
              "  'three',\n",
              "  '.',\n",
              "  'four',\n",
              "  '.',\n",
              "  'five',\n",
              "  '.',\n",
              "  'six',\n",
              "  '.',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'ten',\n",
              "  '.',\n",
              "  'eleven',\n",
              "  '.',\n",
              "  'twelve',\n",
              "  '.',\n",
              "  'thirteen',\n",
              "  '.',\n",
              "  'fourteen',\n",
              "  '.',\n",
              "  'fifteen',\n",
              "  '.',\n",
              "  'sixteen',\n",
              "  '.',\n",
              "  'seventeen',\n",
              "  '.',\n",
              "  'eighteen',\n",
              "  '.',\n",
              "  'nineteen',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'twenty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'thirty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'forty',\n",
              "  '.',\n",
              "  'forty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'forty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'forty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'forty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'forty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'forty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'forty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'forty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'forty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'fifty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'sixty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  'one',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  'two',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  'three',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  'four',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  'five',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  'six',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'seventy',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'eighty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  'one',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  'two',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  'three',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  'four',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  'five',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  'six',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'ninety',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'one',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'two',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'three',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'four',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'five',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'six',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ten',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eleven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twelve',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirteen',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fourteen',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifteen',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixteen',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventeen',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighteen',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'nineteen',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'sixty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  'one',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  'two',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  'three',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  'four',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  'five',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  'six',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'seventy',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'eighty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  'one',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  'two',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  'three',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  'four',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  'five',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  'six',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'one',\n",
              "  'hundred',\n",
              "  'ninety',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'one',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'two',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'three',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'four',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'five',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'six',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'ten',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'eleven',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twelve',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirteen',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'fourteen',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'fifteen',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'sixteen',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'seventeen',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'eighteen',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'nineteen',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'twenty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'thirty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'six',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'seven',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'eight',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'forty',\n",
              "  'nine',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'one',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'two',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'three',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'four',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'five',\n",
              "  '.',\n",
              "  'two',\n",
              "  'hundred',\n",
              "  'fifty',\n",
              "  'six',\n",
              "  ...],\n",
              " (#63095) [0,1,2,1,3,1,4,1,5,1...])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L((tokens[i:i+3], tokens[i+3]) for i in range(0,len(tokens)-4,3))\n",
        "# independent variable - dependent variables\n",
        "# ['one', '.', 'two'], '.'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eJj5QWMJXzX",
        "outputId": "213a30cd-98c9-4051-ca86-70d66d0713d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0,len(nums)-4,3))\n",
        "seqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXdN-BbTJbJN",
        "outputId": "1225c293-24ca-40c8-a264-b82c00fc68e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 64\n",
        "cut = int(len(seqs) * 0.8) # first 80% training set rest 20% for validation set\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)"
      ],
      "metadata": {
        "id": "wRA5PsWuJ3ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create neural netwrok architecture \n",
        "# 3 layers \n",
        "class LMModel1(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.h_h(self.i_h(x[:,0])))\n",
        "        h = h + self.i_h(x[:,1])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        h = h + self.i_h(x[:,2])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "metadata": {
        "id": "Q4Q9sQj4J__-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel1(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "rBS_8xhiNlC4",
        "outputId": "11dfe0d1-bb6b-4eaa-9e91-8acadb10416c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.824297</td>\n",
              "      <td>1.970941</td>\n",
              "      <td>0.467554</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.386973</td>\n",
              "      <td>1.823242</td>\n",
              "      <td>0.467554</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.417556</td>\n",
              "      <td>1.654498</td>\n",
              "      <td>0.494414</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.376440</td>\n",
              "      <td>1.650849</td>\n",
              "      <td>0.494414</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n,counts = 0,torch.zeros(len(vocab))\n",
        "for x,y in dls.valid:\n",
        "    n += y.shape[0]\n",
        "    for i in range_of(vocab): counts[i] += (y==i).long().sum()\n",
        "idx = torch.argmax(counts)\n",
        "idx, vocab[idx.item()], counts[idx].item()/n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUv0KGwRNozj",
        "outputId": "1bb714ac-0975-4318-ffa3-fe918f754e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(29), 'thousand', 0.15165200855716662)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = Counter(tokens[cut:])\n",
        "mc = c.most_common(10)\n",
        "mc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOpwcOp2N32f",
        "outputId": "2b9040e2-9c97-4ca2-d20b-9276a8bda0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('thousand', 7104),\n",
              " ('.', 7103),\n",
              " ('hundred', 6405),\n",
              " ('nine', 2440),\n",
              " ('eight', 2344),\n",
              " ('five', 2340),\n",
              " ('six', 2340),\n",
              " ('seven', 2340),\n",
              " ('three', 2339),\n",
              " ('four', 2339)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc[0][1], len(tokens[cut:])\n",
        "mc[0][1]/len(tokens[cut:])\n",
        "# if we have predicted every number is thousand as it appers more tha any other we will be 15% accurate \n",
        "# compare to our model which is close to 50% "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubfnrz10OIKw",
        "outputId": "92e94945-3948-4f19-fb3c-7b36a7578c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15353028894988222"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ('.', 7103)\n",
        "mc[1][1], len(tokens[cut:])\n",
        "mc[1][1]/len(tokens[cut:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL4R6G-0OsZS",
        "outputId": "432ec3be-47d6-4c89-9cdb-3d7060ce7d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15350867714118996"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ('hundred', 6405)\n",
        "mc[2][1], len(tokens[cut:])\n",
        "mc[2][1]/len(tokens[cut:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz-WMwb-O171",
        "outputId": "46a3044d-e2e0-4562-e880-2aef82cc3c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13842363467398586"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ('seven', 2340)\n",
        "mc[7][1], len(tokens[cut:])\n",
        "mc[7][1]/len(tokens[cut:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6g9w9fxO_9p",
        "outputId": "44e0491d-7bd4-4968-84c7-818779282c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05057163233991053"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recurrent Neural Network"
      ],
      "metadata": {
        "id": "oAj7AsInNw1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel2(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = 0\n",
        "        for i in range(3):\n",
        "            # print(\"-------------------\", i, x[:i])\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "metadata": {
        "id": "YdS487yHPOT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "FGpPbv-SPTQ_",
        "outputId": "868ece13-5c86-426c-908e-e84c727c4fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.823478</td>\n",
              "      <td>1.926430</td>\n",
              "      <td>0.467792</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.402421</td>\n",
              "      <td>1.814042</td>\n",
              "      <td>0.468980</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.418952</td>\n",
              "      <td>1.683436</td>\n",
              "      <td>0.494652</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.390207</td>\n",
              "      <td>1.662460</td>\n",
              "      <td>0.460661</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# improving rnn\n",
        "\n",
        "class LMModel3(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = 0\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for i in range(3):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "        out = self.h_o(self.h)\n",
        "        # h persists from batch to batch we need to reset it for each batch\n",
        "        # gradient history will be reset - back propogation through time BPTT \n",
        "        self.h = self.h.detach() \n",
        "        return out\n",
        "    # at each epoch we are going back to our natural numbers so set to 0\n",
        "    def reset(self): self.h = 0"
      ],
      "metadata": {
        "id": "5ipi31mjQyfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = len(seqs)//bs\n",
        "m,bs,len(seqs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abGa8LhXSMi9",
        "outputId": "899895e0-390b-4e57-a5b6-145f77f51c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(328, 64, 21031)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def group_chunks(ds, bs):\n",
        "    m = len(ds) // bs\n",
        "    new_ds = L()\n",
        "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
        "    return new_ds"
      ],
      "metadata": {
        "id": "3ChnQXYCSYXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(\n",
        "    group_chunks(seqs[:cut], bs), \n",
        "    group_chunks(seqs[cut:], bs), \n",
        "    bs=bs, drop_last=True, shuffle=False)"
      ],
      "metadata": {
        "id": "Ve3intjkSa0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel3(len(vocab), 64), loss_func=F.cross_entropy,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "T3PT_KhTSdSd",
        "outputId": "e1528617-3238-41fa-e800-ab303f1793a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.722347</td>\n",
              "      <td>1.807805</td>\n",
              "      <td>0.483654</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.270391</td>\n",
              "      <td>1.752513</td>\n",
              "      <td>0.455048</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.091535</td>\n",
              "      <td>1.593707</td>\n",
              "      <td>0.516106</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.017162</td>\n",
              "      <td>1.575380</td>\n",
              "      <td>0.499279</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.989237</td>\n",
              "      <td>1.612636</td>\n",
              "      <td>0.521154</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.929354</td>\n",
              "      <td>1.645421</td>\n",
              "      <td>0.552885</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.866206</td>\n",
              "      <td>1.588576</td>\n",
              "      <td>0.581731</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.834293</td>\n",
              "      <td>1.633378</td>\n",
              "      <td>0.585337</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.793425</td>\n",
              "      <td>1.750832</td>\n",
              "      <td>0.574038</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.780956</td>\n",
              "      <td>1.721157</td>\n",
              "      <td>0.582452</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instead of just predicting 4 word based on first 3 we will try to predict any word\n",
        "# we will offset sequence by 1 for dependent variable and indenpendent variable\n",
        "# 1 2 3 4 5 \n",
        "# 2 3 4 5 6 \n",
        "sl = 16\n",
        "seqs = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n",
        "         for i in range(0,len(nums)-sl-1,sl))\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n",
        "                             group_chunks(seqs[cut:], bs),\n",
        "                             bs=bs, drop_last=True, shuffle=False)"
      ],
      "metadata": {
        "id": "MDGW0QDaTXKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[L(vocab[o] for o in s) for s in seqs[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ1dDAruTj98",
        "outputId": "0be1cfa9-3e7b-46e5-8317-5c807bd13bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n",
              " (#16) ['.','two','.','three','.','four','.','five','.','six'...]]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel4(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = 0\n",
        "        \n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        for i in range(sl):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "            outs.append(self.h_o(self.h))\n",
        "        self.h = self.h.detach()\n",
        "        return torch.stack(outs, dim=1)\n",
        "    \n",
        "    def reset(self): self.h = 0"
      ],
      "metadata": {
        "id": "a9vluR66TyHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(inp, targ):\n",
        "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
      ],
      "metadata": {
        "id": "S81micHRUFHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(20, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "MeCC4GU-UJTz",
        "outputId": "3a638186-bb33-429b-a229-953a8f65839d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.226497</td>\n",
              "      <td>3.176609</td>\n",
              "      <td>0.157471</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.504166</td>\n",
              "      <td>2.080834</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.842446</td>\n",
              "      <td>1.935876</td>\n",
              "      <td>0.467041</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.512856</td>\n",
              "      <td>1.881448</td>\n",
              "      <td>0.499512</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.333710</td>\n",
              "      <td>1.794642</td>\n",
              "      <td>0.549316</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.184813</td>\n",
              "      <td>1.909202</td>\n",
              "      <td>0.558594</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.073470</td>\n",
              "      <td>1.926587</td>\n",
              "      <td>0.571777</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.954470</td>\n",
              "      <td>1.941545</td>\n",
              "      <td>0.611247</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.855734</td>\n",
              "      <td>1.933198</td>\n",
              "      <td>0.636068</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.780780</td>\n",
              "      <td>1.906064</td>\n",
              "      <td>0.635742</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.720956</td>\n",
              "      <td>2.455930</td>\n",
              "      <td>0.636882</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.681900</td>\n",
              "      <td>1.924057</td>\n",
              "      <td>0.665283</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.622078</td>\n",
              "      <td>2.005405</td>\n",
              "      <td>0.682943</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.578073</td>\n",
              "      <td>2.019791</td>\n",
              "      <td>0.689209</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.555004</td>\n",
              "      <td>2.046687</td>\n",
              "      <td>0.701091</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.538346</td>\n",
              "      <td>2.018703</td>\n",
              "      <td>0.680176</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.510678</td>\n",
              "      <td>2.085854</td>\n",
              "      <td>0.694743</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.490589</td>\n",
              "      <td>1.973790</td>\n",
              "      <td>0.693197</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.479103</td>\n",
              "      <td>2.055916</td>\n",
              "      <td>0.698405</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.471265</td>\n",
              "      <td>2.066590</td>\n",
              "      <td>0.701497</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayers or stacked RNN\n",
        "class LMModel5(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = torch.zeros(n_layers, bs, n_hidden)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(res)\n",
        "    \n",
        "    def reset(self): self.h.zero_()"
      ],
      "metadata": {
        "id": "pfsXjtBdUkxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel5(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "5osOFgeGU5Bt",
        "outputId": "ded559be-aee7-4adc-d4f5-c9ce63dc9cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.989784</td>\n",
              "      <td>2.513293</td>\n",
              "      <td>0.437093</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.123006</td>\n",
              "      <td>1.772213</td>\n",
              "      <td>0.470947</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.692048</td>\n",
              "      <td>1.909070</td>\n",
              "      <td>0.319336</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.464266</td>\n",
              "      <td>1.724511</td>\n",
              "      <td>0.486816</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.309704</td>\n",
              "      <td>1.908625</td>\n",
              "      <td>0.488363</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.165450</td>\n",
              "      <td>2.173341</td>\n",
              "      <td>0.489827</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.039468</td>\n",
              "      <td>2.296848</td>\n",
              "      <td>0.494141</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.941451</td>\n",
              "      <td>2.373549</td>\n",
              "      <td>0.493652</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.845794</td>\n",
              "      <td>2.388737</td>\n",
              "      <td>0.501709</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.763576</td>\n",
              "      <td>2.339804</td>\n",
              "      <td>0.512533</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.704475</td>\n",
              "      <td>2.340133</td>\n",
              "      <td>0.524658</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.663120</td>\n",
              "      <td>2.385452</td>\n",
              "      <td>0.542236</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.634513</td>\n",
              "      <td>2.381259</td>\n",
              "      <td>0.535482</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.617609</td>\n",
              "      <td>2.386733</td>\n",
              "      <td>0.536377</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.608785</td>\n",
              "      <td>2.391607</td>\n",
              "      <td>0.538249</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results are not good as we got before \n",
        "# we have very deep model - which is hard to train \n",
        "# we get exploding or disappearing activations  \n",
        "# explosion is when number becomes too big \n",
        "# disappearing is when number becomes too small "
      ],
      "metadata": {
        "id": "qF_BMCZnVF2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# solution use architecture LSTM\n",
        "\n",
        "class LSTMCell(Module):\n",
        "    def __init__(self, ni, nh):\n",
        "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
        "        self.input_gate  = nn.Linear(ni + nh, nh)\n",
        "        self.cell_gate   = nn.Linear(ni + nh, nh)\n",
        "        self.output_gate = nn.Linear(ni + nh, nh)\n",
        "\n",
        "    def forward(self, input, state):\n",
        "        h,c = state\n",
        "        h = torch.cat([h, input], dim=1)\n",
        "        forget = torch.sigmoid(self.forget_gate(h))\n",
        "        c = c * forget\n",
        "        inp = torch.sigmoid(self.input_gate(h))\n",
        "        cell = torch.tanh(self.cell_gate(h))\n",
        "        c = c + inp * cell\n",
        "        out = torch.sigmoid(self.output_gate(h))\n",
        "        h = out * torch.tanh(c)\n",
        "        return h, (h,c)"
      ],
      "metadata": {
        "id": "9d2qgC8iWTGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCell(Module):\n",
        "    def __init__(self, ni, nh):\n",
        "        self.ih = nn.Linear(ni,4*nh)\n",
        "        self.hh = nn.Linear(nh,4*nh)\n",
        "\n",
        "    def forward(self, input, state):\n",
        "        h,c = state\n",
        "        # One big multiplication for all the gates is better than 4 smaller ones\n",
        "        gates = (self.ih(input) + self.hh(h)).chunk(4, 1)\n",
        "        ingate,forgetgate,outgate = map(torch.sigmoid, gates[:3])\n",
        "        cellgate = gates[3].tanh()\n",
        "\n",
        "        c = (forgetgate*c) + (ingate*cellgate)\n",
        "        h = outgate * c.tanh()\n",
        "        return h, (h,c)"
      ],
      "metadata": {
        "id": "ALcQIU8uWi9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.arange(0,10); t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9klotmUbWlj9",
        "outputId": "0abbde4e-8f75-4a7b-a0a3-8da416000ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.chunk(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgiTrrEQWnrZ",
        "outputId": "a43effa6-f6b4-4af1-f873-4a4d6b4658c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 4]), tensor([5, 6, 7, 8, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel6(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(res)\n",
        "    \n",
        "    def reset(self): \n",
        "        for h in self.h: h.zero_()"
      ],
      "metadata": {
        "id": "bhgJzWoKWs3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel6(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 1e-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "sR4VpczgWwDm",
        "outputId": "3033babd-6891-4bd0-ada7-55b20eb70c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.997656</td>\n",
              "      <td>2.740257</td>\n",
              "      <td>0.427979</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.190678</td>\n",
              "      <td>1.936098</td>\n",
              "      <td>0.321370</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.618659</td>\n",
              "      <td>1.815960</td>\n",
              "      <td>0.480062</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.313747</td>\n",
              "      <td>2.088989</td>\n",
              "      <td>0.529216</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.050850</td>\n",
              "      <td>1.999131</td>\n",
              "      <td>0.617676</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.718113</td>\n",
              "      <td>1.642511</td>\n",
              "      <td>0.737142</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.407751</td>\n",
              "      <td>1.448469</td>\n",
              "      <td>0.753662</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.210455</td>\n",
              "      <td>1.317910</td>\n",
              "      <td>0.759115</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.111644</td>\n",
              "      <td>1.164466</td>\n",
              "      <td>0.790039</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.065864</td>\n",
              "      <td>1.110025</td>\n",
              "      <td>0.807943</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.041896</td>\n",
              "      <td>1.157400</td>\n",
              "      <td>0.810303</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.028247</td>\n",
              "      <td>1.148804</td>\n",
              "      <td>0.811768</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.021164</td>\n",
              "      <td>1.110234</td>\n",
              "      <td>0.813883</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.017498</td>\n",
              "      <td>1.124640</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.015802</td>\n",
              "      <td>1.124562</td>\n",
              "      <td>0.812663</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularizing an LSTM\n",
        "# to ensuer we dont overfit \n",
        "# Dropout - regularization technique\n",
        "# randomly delete activation on each batch \n",
        "\n",
        "class Dropout(Module):\n",
        "    def __init__(self, p): self.p = p\n",
        "    def forward(self, x):\n",
        "        if not self.training: return x\n",
        "        mask = x.new(*x.shape).bernoulli_(1-p)\n",
        "        return x * mask.div_(1-p)"
      ],
      "metadata": {
        "id": "xZ8ArrDuW131"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation Regularization and Temporal Activation Regularization"
      ],
      "metadata": {
        "id": "FvxdS2L3ZFJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel7(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "        \n",
        "    def forward(self, x):\n",
        "        raw,h = self.rnn(self.i_h(x), self.h)\n",
        "        out = self.drop(raw)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(out),raw,out\n",
        "    \n",
        "    def reset(self): \n",
        "        for h in self.h: h.zero_()"
      ],
      "metadata": {
        "id": "-g8wO_DSZpYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel7(len(vocab), 64, 2, 0.5),\n",
        "                loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n",
        "                cbs=[ModelResetter, RNNRegularizer(alpha=2, beta=1)])"
      ],
      "metadata": {
        "id": "Hobli7EMZvkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = TextLearner(dls, LMModel7(len(vocab), 64, 2, 0.4),\n",
        "                    loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
      ],
      "metadata": {
        "id": "6rAED6bkZ1PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "mIkYgU-vZ5d-",
        "outputId": "35fc1d4e-d929-4016-da4e-5131f4d78e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.012636</td>\n",
              "      <td>0.666969</td>\n",
              "      <td>0.842285</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.027867</td>\n",
              "      <td>0.663418</td>\n",
              "      <td>0.819417</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.035776</td>\n",
              "      <td>1.032247</td>\n",
              "      <td>0.806152</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.040214</td>\n",
              "      <td>0.813783</td>\n",
              "      <td>0.850342</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.028341</td>\n",
              "      <td>0.650990</td>\n",
              "      <td>0.852295</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.022422</td>\n",
              "      <td>0.739949</td>\n",
              "      <td>0.833496</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.022070</td>\n",
              "      <td>0.780746</td>\n",
              "      <td>0.844157</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.017627</td>\n",
              "      <td>0.759494</td>\n",
              "      <td>0.842285</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.015892</td>\n",
              "      <td>0.656404</td>\n",
              "      <td>0.849935</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.013619</td>\n",
              "      <td>0.746668</td>\n",
              "      <td>0.848470</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.010770</td>\n",
              "      <td>0.709698</td>\n",
              "      <td>0.848796</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.009281</td>\n",
              "      <td>0.653121</td>\n",
              "      <td>0.853516</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.007733</td>\n",
              "      <td>0.751514</td>\n",
              "      <td>0.850016</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.006882</td>\n",
              "      <td>0.709430</td>\n",
              "      <td>0.851888</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.006176</td>\n",
              "      <td>0.723073</td>\n",
              "      <td>0.851888</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}